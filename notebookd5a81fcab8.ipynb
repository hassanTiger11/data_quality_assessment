{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1451728,"sourceType":"datasetVersion","datasetId":850967}],"dockerImageVersionId":30004,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Quality Assessment for a Medium Size Bikes & Cycling Accessories Organization\n\n> This project was done under the umbrella of KPMG internship experience. I was provided data sets of an organization targeting a client who wants a feedback from us on their dataset quality and how this can be improved.\n\n### Purpose \nPrimarily, Sprocket Central Pty Ltd needs help with its customer and transactions data. The organisation has a large dataset relating to its customers, but their team is unsure how to effectively analyse it to help optimise its marketing strategy. \n\n“the importance of optimising the quality of customer datasets cannot be underestimated. The better the quality of the dataset, the better chance you will be able to use it drive company growth.” \n\nPerform the preliminary data exploration and identify ways to improve the quality of Sprocket Central Pty Ltd’s data.\n\n### Datasets\nThe client provided KPMG with 3 datasets:\n- Customer Demographic \n- Customer Addresses\n- Transactions data in the past 3 months\n\n### Data Quality Framework Table\nUsing the dimensions included in the Data Quality Framework, I will assess the quality of these datasets. Followings are the dimesnions provided by the Data Quality Framework: \n- Completeness : How much information all entities have. Number of missing values.\n- Consistency : How conistent is your Data. Number of inconsistencies in your data.\n- Accuarcy : How accurate is your Data. Number of errors in you data.\n- Relevancy/Auditability : Relevanct data in your entities. Number of irrelavant values.\n- Validity : Validated data with allowable values.\n- Uniqueness: How much uniques is your data. Number of duplicated values.\n- Timeliness: Updated data. Current data.\n","metadata":{}},{"cell_type":"code","source":"# importing pandas library for i/o and dataframes \nimport pandas as pd\n\n# loading dataset and extracting sheets'\ndataset = pd.ExcelFile('../input/raw-data-provided-by-organization/Raw_Data_provided_by_Organisation.xlsx')\n\n# parsing sheets\nTransactions = dataset.parse('Transactions', header=0)\nNewCustomerList = dataset.parse('NewCustomerList')\nCustomerDemographic = dataset.parse('CustomerDemographic')\nCustomerAddress = dataset.parse('CustomerAddress')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring and Analyzing Data Quality of Sheet: Transactions ","metadata":{}},{"cell_type":"code","source":"# display data inside sheet\nprint(Transactions.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking Consistency and Validity of Dataset","metadata":{}},{"cell_type":"code","source":"# Display columns of dataset Transactions\nprint(Transactions.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the shape of your data\nprint(Transactions.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Highlights of Consistency and Validity in Transactions\nTransactions dataset has 20000 records with 13 columns. \n- Out of which, 3 are of datatype **int64** which are keys. \n- One is the date **datetime64** in format **MM/DD/YYYY**. The date format used to capture DOB of customers is **YYYY-MM-DD**. It would be better if it is kept consistent.\n- Another one is Online Order which is captured in a column of **float64** datatype, however the values are **boolean**, that is true and false. \n- 5 columns are of datatype **object** which are order_status, brand, product_line, product_class, product_size. \n- Last 3 columns are of datatype **float64** again from which one of them is a date and should be **datetime64** and must be in the standard format.","metadata":{}},{"cell_type":"markdown","source":"## Checking Completeness of Dataset","metadata":{}},{"cell_type":"code","source":"# looking for the null values\ntotal_null_values = Transactions.isnull().sum()\n\n# calculating total values\ntotal_values = Transactions.count().sort_values(ascending=True) \n\n# calculating the percentage of null values\nnull_values_percentage = total_null_values/total_values *100\n\n# converting to dataframe of missing values\nmissing_values = pd.concat({'Total Values' : total_values, 'Null_values': total_null_values, 'Percentage of Missing Values': null_values_percentage}, axis=1)\n\n# display missing values\nprint(missing_values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Highlights of Completeness in Transactions\n- Order Online columns has about 1.83% of null values. There are 360 records in which order_online was not captured.\n- Columns brand, product_line, product_class, product_size, standard_cost, product_first_sold_date also has a percentage of 0.995% missing values that is 197 null values, which should not be missing if product_id is inherited and the details of the product cannot be missing.","metadata":{}},{"cell_type":"markdown","source":"## Checking Accuracy of Dataset","metadata":{}},{"cell_type":"code","source":"# checking a single product id and its details\nbool_series = Transactions['product_id'] == 0\n\nproduct_id_0 = Transactions[bool_series]\n\n#view the product details\nprint(product_id_0[['brand', 'product_line','product_class']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Highlights of Accuracy in Transactions\nA single product ID should be referencing a single product with unique values.","metadata":{}},{"cell_type":"markdown","source":"## Checking Uniqueness of Dataset","metadata":{}},{"cell_type":"code","source":"# looking for duplicated values\nduplicated_values = Transactions.duplicated()\n\n# number of duplicated values in dataset\nprint(\"The number of duplicated records in Transactions dataset is {}\".format(duplicated_values.sum()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Highlights of Uniqueness in Transactions\nTransaction records are unique.","metadata":{}},{"cell_type":"markdown","source":"## Exploring and Analyzing Data Quality of Sheet: NewCustomerList, Customer Demographic and Customer Address","metadata":{}},{"cell_type":"code","source":"# display data of sheet NewCustomerList\nprint(NewCustomerList.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display data of sheet Customer Demographic\nprint(CustomerDemographic.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display data of sheet Customer Address\nprint(CustomerAddress.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking Consistency and Validity of Datasets","metadata":{}},{"cell_type":"code","source":"# Display columns of dataset NewCustomerList\nprint(NewCustomerList.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the shape of your data\nprint(NewCustomerList.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display columns of dataset CustomerDemographic\nprint(CustomerDemographic.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display columns of dataset CustomerAddress\nprint(CustomerAddress.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the shape of your data\nprint(CustomerDemographic.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the shape of your data\nprint(CustomerAddress.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Highlights of Consistency and Validity in NewCustomerList, Customer Demographic and Customer Address\nNewCustomerList dataset has 1000 records with 23 columns, yet Customer Demographics have 4000 records with 13 columns and remaining in Customer Address with 6 columns using **customer_id** has key.\n- Structure format of NewCustomerList must be consistent with Customer Demographic and Customer Address.\n- There is no **customer_id** in NewCustomerList.\n- Number of columns are inconsistent because in NewCustomerList there are **4 columns which are Unnamed** and they contain some values as well, however are not labeled so cannot be identified.\n- There is one column in *NewCustomerList* which is **Value**, it is captured in a column of **float64** datatype but this was not captured before and is not present in *CustomerDemographic* or *CustomerAddress*.\n- There is one column named **default** in *CustomerDemographic*, it is captured in a column of **object** datatype, some values are observed to be date values but this was not captured after and is not present in *NewCustomerList*. \n- From remaining columns 5 columns are of datatype **int64** which are past_3_years_bike_related_purchases, tenure, postcode, property_valuation, and Rank.                                . \n- DOB is the date column **datetime64** in format **YYYY-MM-DD**. The date format used to capture transaction date in Transactions is **MM/DD/YYYY**. It would be better if it is kept consistent.\n- Rest of the columns are in **object** data type values but, deceased_indicator must have contain **boolean** like True and False.\n- Data Captured in Gender column in the dataset CustomerDemographic is not consistent. It should be \"Male\", \"Female\" and \"U\" as per the NewCustomerList.","metadata":{}},{"cell_type":"markdown","source":"## Checking Completeness of Datasets","metadata":{}},{"cell_type":"code","source":"# looking for the null values\ntotal_null_values = NewCustomerList.isnull().sum()\n\n# calculating total values\ntotal_values = NewCustomerList.count().sort_values(ascending=True) \n\n# calculating the percentage of null values\nnull_values_percentage = total_null_values/total_values *100\n\n# converting to dataframe of missing values\nmissing_values_NewCustomerList = pd.concat({'Total Values' : total_values, 'Null_values': total_null_values, 'Percentage of Missing Values': null_values_percentage}, axis=1)\n\n# display missing values\nprint(missing_values_NewCustomerList)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looking for the null values\ntotal_null_values = CustomerDemographic.isnull().sum()\n\n# calculating total values\ntotal_values = CustomerDemographic.count().sort_values(ascending=True) \n\n# calculating the percentage of null values\nnull_values_percentage = total_null_values/total_values *100\n\n# converting to dataframe of missing values\nmissing_values_CustomerDemographic = pd.concat({'Total Values' : total_values, 'Null_values': total_null_values, 'Percentage of Missing Values': null_values_percentage}, axis=1)\n\n# display missing values\nprint(missing_values_CustomerDemographic)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Highlights of Completeness in NewCustomerList, Customer Demographic and Customer Address\n- In NewCustomerList 19.76% of job_industry_category values are missing almost similar to CustomerDemographic which is 19.61%.\n- 11.85% of job_title values are missing in NewCustomerList a little less as compared to CustomerDemographic that has 14.48% of missing values.\n- 3.22% of last_name values were missing in CustomerDemographic yet 2.98% of last_name values are missing in NewCustomerList.\n- CustomerDemographic has 2.22% of missing DOB values which is slighlty decreased to 1.72% NewCustomerList.\n- There is a 2.22% of missing tenure values in CustomerDemographic but there is no missing values of tenure in NewCustomerList.\n- There is 1 missing record of address of **customer_id = 3** in CustomerAddress, as per identified by the shape of the datasets.\n","metadata":{}},{"cell_type":"markdown","source":"## Checking Accuracy of Dataset","metadata":{}},{"cell_type":"code","source":"CustomerDemographic['DOB']","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Highlights of Accuracy in NewCustomerList, Customer Demographic and Customer Address\nOne date value is wrong. 1843 year is not possible.","metadata":{}},{"cell_type":"markdown","source":"## Checking Uniqueness of Dataset","metadata":{}},{"cell_type":"code","source":"# looking for duplicated values\nduplicated_values = NewCustomerList.duplicated()\n\n# number of duplicated values in dataset\nprint(\"The number of duplicated records in NewCustomerList dataset is {}\".format(duplicated_values.sum()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looking for duplicated values\nduplicated_values = CustomerDemographic.duplicated()\n\n# number of duplicated values in dataset\nprint(\"The number of duplicated records in CustomerDemographic dataset is {}\".format(duplicated_values.sum()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looking for duplicated values\nduplicated_values = CustomerAddress.duplicated()\n\n# number of duplicated values in dataset\nprint(\"The number of duplicated records in CustomerAddress dataset is {}\".format(duplicated_values.sum()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Highlights of Uniqueness\nAll records are unique.","metadata":{}}]}